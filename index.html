<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta name="google-site-verification" content="xDNWUvx6Q5EWK5YYSyKvK8DZTmvXhKsGX203Ll-BFFE" >
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <title>Kim Youwang</title>
    <link rel="stylesheet" type="text/css" id="defaultstyle" href="./style.css"/>
    <script type="text/javascript" src="js/tracker.js"></script>
    <script type="text/javascript" src="js/pageturner.js"></script>
  </head>
  <script src="script/functions.js"></script>
  <body>
    <div class="container">

      <div class="intro">

<!--        <p>-->
        <h1 style="margin-bottom:0.25em;">Kim Youwang</h1>
        <small style="color:gray">youwang.kim@postech.ac.kr</small>
        <p>
        <img src="media/profile_231009.jpeg" alt="Kim Youwang"/>
            I am a Ph.D. student at <a href="https://ami.kaist.ac.kr/" target="_blank">AMILab</a> at <a href="https://kaist.ac.kr/en" target="_blank">KAIST</a>, advised by <a href="https://ami.kaist.ac.kr/members/tae-hyun-oh" target="_blank">Tae-Hyun Oh</a>.
            I was a research scientist intern at <a href="https://about.meta.com/realitylabs/codecavatars/?utm_source=about.facebook.com&utm_medium=redirect" target="_blank"> Meta Reality Labs - Codec Avatars team</a>, working with <a href="https://sites.google.com/site/zjucaochen/home" target="_blank">Chen Cao</a>, <a href="https://www.linkedin.com/in/jovan-cmu/" target="_blank">Jovan Popović</a>, and <a href="https://www.linkedin.com/in/yaser-sheikh-9847a64/" target="_blank">Yaser Sheikh</a>.
            I have a close research collaboration with <a href="https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html" target="_blank">Gerard Pons-Moll</a>, and was a visiting researcher at <a href="https://virtualhumans.mpi-inf.mpg.de/" target="_blank">Real Virtual Humans Group</a> at the <a href="https://uni-tuebingen.de/" target="_blank">Univ. of Tübingen</a>.
            I received my bachelor's degree in Electrical Engineering from POSTECH.
        </p>
        <p>
            I work on research projects at the intersection of computer graphics, vision, and machine learning.
            My research interests are the generative modeling of 3D/4D virtual humans, animals, and objects by understanding their realistic shapes and appearances.
<!--            During my bachelor, I spent a semester at <a href="https://www.ntu.edu.sg/">Nanyang Technological University (NTU)</a> as an exchange student.-->
        </p>
        <p>
<!--          <a class="a_more" href="mailto:youwang.kim@postech.ac.kr">youwang.kim@postech.ac.kr</a> |-->
<!--          <br>-->
          <a class="a_more" href="https://www.overleaf.com/read/prgrxsxzmkwd" target="_blank">CV</a> |
          <a class="a_more" href="https://scholar.google.com/citations?user=gKXTrF8AAAAJ&hl=en" target="_blank">Google Scholar</a> |
          <a class="a_more" href="https://www.linkedin.com/in/kim-youwang/" target="_blank">LinkedIn</a> |
          <a class="a_more" href="https://github.com/Youwang-Kim" target="_blank">GitHub</a>
        </p>

      </div> <!-- intro -->


      <table>
        <tr>
          <td width="22%" valign="middle">
            <img src="media/postech_logo.png" width="97%">
          </td>
          <td width="12%" valign="middle">
            <img src="media/ami_logo.png" width="90%">
          </td>
          <td width="17%" valign="middle">
            <img src="media/Meta.png" width="90%">
          </td>
          <td width="8%" valign="middle">
            <img src="media/Reality_Labs_logo.png" width="75%">
          </td>
          <td width="17%" valign="middle">
            <img src="media/University_Tuebingen.png" width="80%">
          </td>
          <td width="24%" valign="middle"></td>
        </tr>
      </table>


      <h2>News</h2>
        <ul>
            <li class="yw_list"><b>02/2025</b> Our paper on <a href="https://arxiv.org/abs/2403.14539v2" target="_blank">occlusion-robust 3D shape estimation</a> is accepted to CVPR 2025.</li>
            <li class="yw_list"><b>12/2024</b> Our paper <a href="https://kim-youwang.github.io/neuface" target="_blank">NeuFace</a> got <a href="https://blog.iclr.cc/2024/08/22/iclr2025-tmlr-partnership/" target="_blank">invited to ICLR2025</a> as a poster presentation.<br></li>
            <li class="yw_list"><b>11/2024</b> Our BMVC2024 paper <a href="https://metta3d.github.io/" target="_blank">MeTTA</a> won the best poster award at BMVC2024.<br></li>
            <li class="yw_list"><b>11/2024</b> Our work on large 3D scene stylization won the Excellence Prize at ICT paper awards.<br></li>
            <li class="yw_list"><b>10/2024</b> I started research scientist internship at <a href="https://about.meta.com/realitylabs/codecavatars/?utm_source=about.facebook.com&utm_medium=redirect" target="_blank">Meta Reality Labs - Codec Avatars team</a>.</li>
            <li class="yw_list"><b>07/2024</b> Our paper on <a href="https://openreview.net/forum?id=zVDMh6JvWc" target="_blank">large-scale 3D face mesh dataset</a> is accepted to TMLR 2024.</li>
            <li class="yw_list"><b>07/2024</b> Our paper on robust monocular 3D mesh reconstruction is accepted to BMVC 2024.</li>
            <li class="yw_list"><b>07/2024</b> I won the best poster award in POSTECH-KAIST joint ML workshop 2024.</li>
<!--            <li class="yw_list"><b>02/2024</b> I'll be joining <a href="https://about.meta.com/realitylabs/codecavatars/?utm_source=about.facebook.com&utm_medium=redirect" target="_blank">Meta Reality Labs - Codec Avatars team</a> as a research scientist intern, starting this fall.</li>-->
            <li class="yw_list"><b>02/2024</b> Our paper on <a href="https://arxiv.org/abs/2312.11360" target="_blank">text-driven PBR texture synthesis</a> is accepted to CVPR 2024.</li>
        </ul>
  <!--                show more toggle button-->
          <a class="a_more" href="javascript:toggleblock(&#39;old_news&#39;)">---- show more ----</a>
          <div id="old_news" style="display: none;">
              <ul>
                <li class="yw_list"><b>12/2023</b> Our paper on efficient 3D scene stylization is accepted to AAAI 2024. </li>
                <li class="yw_list"><b>11/2023</b> I won the Grand Prize (1st place, Minister's award, $12,000) at ICT paper awards 2023. </li>
                <li class="yw_list"><b>10/2023</b> I am selected as an <a href="https://iccv2023.thecvf.com/outstanding.reviewers-118.php" target="_blank">outstanding reviewer</a> for ICCV 2023. </li>
                <li class="yw_list"><b>10/2023</b> I am joining <a href="https://virtualhumans.mpi-inf.mpg.de/" target="_blank">Real Virtual Humans Group</a> as a visiting Ph.D. student.</li>
                <li class="yw_list"><b>08/2023</b> Our paper on text-driven human avatar generation is accepted to ICCVW 2023. </li>
                <li class="yw_list"><b>04/2023</b> Our paper on 3D face mesh recon. on videos is accepted to CVPRW 2023. </li>
                <li class="yw_list"><b>02/2023</b> Invited to give a talk on text-driven 4D human avatars at <a href="http://innerverz.io/" target="_blank">INNERVERZ</a>. </li>
                <li class="yw_list"><b>01/2023</b> Our <a href="https://link.springer.com/article/10.1007/s00371-023-02798-x" target="_blank">paper</a> on lightweight body mesh recon. is accepted to TVCJ 2023. </li>
                <li class="yw_list"><b>11/2022</b> Our paper <a href="https://clip-actor.github.io" target="_blank">CLIP-Actor</a> is selected as the winner of <a href="https://www.qualcomm.com/research/university-relations/innovation-fellowship/2022-south-korea" target="_blank">Qualcomm Innovation Fellowship Korea</a>!</li>
                <li class="yw_list"><b>07/2022</b> Our two papers, <a href="https://clip-actor.github.io" target="_blank">CLIP-Actor</a> and <a href="https://fastmetro.github.io" target="_blank">FastMETRO</a>, are accepted to ECCV 2022.</li>
                <li class="yw_list"><b>04/2022</b> I got accepted to <a href="https://iplab.dmi.unict.it/icvss2022/" target="_blank">ICVSS 2022</a>, and I will visit Sicily, Italy this summer. </li>
                <li class="yw_list"><b>10/2021</b> Our paper <a href="https://demr.github.io" target="_blank">DeMR</a> is accepted to BMVC 2021.</li>
              </ul>
          </div>

        <h2>Research Experiences</h2>
        <ul>
            <li class="exp_list"><b>Meta Reality Labs - Codec Avatars team</b>, Pittsburgh, PA.<span style="float: right;">Oct 2024 - Mar 2025</span><br>
                &nbsp&nbsp Research scientist intern, working with <a href="https://sites.google.com/site/zjucaochen/home" target="_blank">Chen Cao</a>, <a href="https://www.linkedin.com/in/jovan-cmu/" target="_blank">Jovan Popović</a>, and <a href="https://www.linkedin.com/in/yaser-sheikh-9847a64/" target="_blank">Yaser Sheikh</a>.<br>
            </li>
            <li class="exp_list"><b>University of Tübingen - Real Virtual Humans group</b>, Tübingen, Germany.<span style="float: right;">Sep 2023 - Present</span><br>
                &nbsp&nbsp Worked as a visiting researcher. Ongoing research collaboration with <a href="https://virtualhumans.mpi-inf.mpg.de/people/pons-moll.html" target="_blank">Gerard Pons-Moll</a>.<br/>
            </li>
            <li class="exp_list"><b>POSTECH - Algorithmic Machine Intelligence lab</b>, Pohang, Korea.<span style="float: right;">Sep 2020 - Present</span><br>
                &nbsp&nbsp Graduate student, working with <a href="https://ami.kaist.ac.kr/members/tae-hyun-oh" target="_blank">Tae-Hyun Oh</a>.<br/>
            </li>
        </ul>

      <h2>Publications</h2>

      <div class="item">
        <img src='./media/fpgs.gif'/>
        <p>
          <b class="title">FPGS: Feed-Forward Semantic-aware Photorealistic Style Transfer of Large-Scale Gaussian Splatting</b><br/>
          GeonU Kim, <u>Kim Youwang</u>, Lee Hyoseok, Tae-Hyun Oh<br/>
          <i>arXiv 2025</i><br/>
            <a href="https://kim-geonu.github.io/FPGS/" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2503.09635" target="_blank">Paper</a> |
            <a href="https://github.com/kaist-ami/" target="_blank">Code(TBA)</a><br>
        </p>
      </div>

      <div class="item">
        <img src='./media/robust3drecon.png'/>
        <p>
          <b class="title">Robust 3D Shape Reconstruction in Zero-Shot from a Single Image in the Wild</b><br/>
          Junhyeong Cho, <u>Kim Youwang</u>, Hunmin Yang, Tae-Hyun Oh<br/>
          <i>CVPR 2025</i><br/>
            <a href="https://zeroshape-w.github.io/" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2403.14539v2" target="_blank">Paper</a><br>
        </p>
      </div>

      <div class="item">
        <img src='./media/4d_face.gif'/>
        <p>
          <b class="title">A Large-Scale 3D Face Mesh Video Dataset via Neural Re-parameterized Optimization</b><br/>
          <u>Kim Youwang</u>, Lee Hyun*, Kim Sung-Bin*, Suekyeong Nam, Janghoon Ju, Tae-Hyun Oh<br/>
          <i>ICLR 2025 / TMLR 2024</i><br/>
            <a href="https://kim-youwang.github.io/neuface" target="_blank">Project page</a> |
<!--            <a href="https://arxiv.org/abs/2310.03205" target="_blank">Paper</a> |-->
            <a href="https://openreview.net/forum?id=zVDMh6JvWc" target="_blank">Paper</a> |
            <a href="https://github.com/kaist-ami/NeuFace" target="_blank">Code</a><br>
          <small style="color:gray;margin-bottom: 0.0em">- Invited to ICLR 2025 for poster presentation (Top 5% TMLR papers invited)</small><br>
        </p>
      </div>

      <div class="item">
        <img src='./media/paint_it.jpg'/>
        <p>
          <b class="title">Paint-it: Text-to-Texture Synthesis via Deep Convolutional Texture Map Optimization and Physically-Based Rendering</b><br/>
          <u>Kim Youwang</u>, Tae-Hyun Oh, Gerard Pons-Moll<br/>
          <i>CVPR 2024</i><br/>
            <a href="https://kim-youwang.github.io/paint-it" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2312.11360" target="_blank">Paper</a> |
            <a href="https://youtu.be/uSKK-ekVJLg" target="_blank">Video</a> |
            <a href="https://github.com/kaist-ami/paint-it" target="_blank">Code</a> |
            <a href="https://www.dropbox.com/scl/fi/4plpanxqy0lo16d3d8t8p/cvpr24_poster_youwang_final.pdf?rlkey=gah19krwju0clqdsep6g3qd4w&st=x831q8a5&dl=0" target="_blank">Poster</a><br/>
<!--          <span style="color:#BB2222;">- Presented in AI for Content Creation Workshop (AI4CC) at CVPR 2024</span><br/>-->
          <small style="color:gray;margin-bottom: 0.0em">- Best Poster Award at POSTECH-KAIST joint ML workshop 2024</small><br>
          <small style="color:gray;margin-bottom: 0.0em">- Presented in AI for Content Creation Workshop (AI4CC) at CVPR 2024</small><br>
          <small style="color:gray;margin-bottom: 0.0em">- Presented in AI for 3D Generation Workshop (AI3DG) at CVPR 2024</small>
        </p>
      </div>

      <div class="item">
        <img src='./media/obj_mesh.gif'/>
        <p>
          <b class="title">MeTTA: Single-View to 3D Textured Mesh Reconstruction with Test-Time Adaptation</b><br/>
          Kim Yu-Ji, Hyunwoo Ha, <u>Kim Youwang</u>, Jaeheung Surh, Hyowon Ha, Tae-Hyun Oh<br>
          <i>BMVC 2024</i><br/>
            <a href="https://metta3d.github.io/" target="_blank">Project page</a><br>
          <small style="color:gray;margin-bottom: 0.0em">- Best Poster Award at BMVC 2024</small><br>
        </p>
      </div>

      <div class="item">
        <img src='./media/syn3d.png'/>
        <p>
          <b class="title">ObjectDR: Object-Centric Domain Randomization for 3D Shape Reconstruction in the Wild</b><br/>
          Junhyeong Cho, <u>Kim Youwang</u>, Hunmin Yang, Tae-Hyun Oh<br/>
          <i>CVPRW 2024</i><br/>
            <a href="https://objectdr.github.io/" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2403.14539v1" target="_blank">Paper</a>
        </p>
      </div>

      <div class="item">
        <img src='./media/clip-actor-x.jpg'/>
        <p>
          <b class="title">CLIP-Actor-X: Text-driven 4D Human Avatar Generation via Cross-modal Synthesis-through-Optimization</b><br/>
          <u>Kim Youwang</u>*, Taehyun Byun*, Kim Ji-Yeon, Sungjoon Choi, Tae-Hyun Oh<br/>
          <i>Journal under review</i><br/>
        </p>
      </div>

      <div class="item">
        <img src='./media/fprf.gif'/>
        <p>
          <b class="title">Feed-Forward Photorealistic Style Transfer for Large-Scale 3D Neural Radiance Fields</b><br/>
          GeonU Kim, <u>Kim Youwang</u>, Tae-Hyun Oh<br/>
          <i>AAAI 2024</i><br/>
            <a href="https://kim-geonu.github.io/FPRF/" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2401.05516" target="_blank">Paper</a> |
            <a href="https://github.com/kaist-ami/FPRF" target="_blank">Code</a><br>
          <small style="color:gray;margin-bottom:0.0em">- Excellence Prize ($2K) at ICT paper awards 2024 </small><br/>
        </p>
      </div>

      <div class="item">
        <img src='./media/tex_avatar.gif'/>
        <p>
          <b class="title">Text-driven Human Avatar Generation by Neural Re-parameterized Texture Optimization</b><br/>
          <u>Kim Youwang</u>, Tae-Hyun Oh<br/>
          <i>ICCVW 2023</i><br/>
            <a href="https://ai3dcc.github.io/papers/0042_camready.pdf" target="_blank">Paper</a> |
            <a href="https://ai3dcc.github.io/posters/0042_poster.pdf" target="_blank">Poster</a><br/>

        </p>
      </div>

      <div class="item">
        <img src='./media/stream.gif'/>
        <p>
          <b class="title">STREAM: Spatio-Temporally Consistent Face Mesh Reconstruction on Videos</b><br/>
          <u>Kim Youwang</u>, Lee Hyun*, Kim Sung-Bin*, Suekyeong Nam, Janghoon Ju, Tae-Hyun Oh<br/>
          <i>CVPRW 2023</i><br/>
          <a href="https://3dmv2023.github.io/assets/posters/14.pdf" target="_blank">Poster</a><br/>
        </p>
      </div>

      <div class="item">
        <img src='./media/rank_pruning.jpg'/>
        <p>
          <b class="title">Multi-stage Adaptive Rank Statistic Pruning for Lightweight Human 3D Mesh Recovery Model</b><br/>
          Dong Hun Ryou, <u>Kim Youwang</u>, Tae-Hyun Oh<br/>
          <i>The Visual Computer Journal (TVCJ) 2023</i><br/>
            <a href="https://link.springer.com/article/10.1007/s00371-023-02798-x" target="_blank">Paper</a>
        </p>
      </div>

      <div class="item">
        <img src='./media/clip_actor.gif'/>
        <p>
          <b class="title">CLIP-Actor: Text-Driven Recommendation and Stylization for Animating Human Meshes</b><br/>
          <u>Kim Youwang</u>*, Kim Ji-Yeon*, Tae-Hyun Oh<br/>
          <i>ECCV 2022</i><br/>
            <a href="https://clip-actor.github.io" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2206.04382" target="_blank">Paper</a> |
            <a href="https://youtu.be/oWr4NP-eVLY" target="_blank">Video</a> |
            <a href="https://github.com/kaist-ami/CLIP-Actor" target="_blank">Code</a> |
            <a href="https://www.dropbox.com/s/8l2jvvc0po6szn7/3229-poster.pdf?dl=0" target="_blank">Poster</a><br/>
            <small style="color:gray;margin-bottom:0.0em">- Grand Prize (1st place, Minister's award, $12K) at ICT paper awards 2023 </small><br/>
            <small style="color:gray;margin-bottom:0.0em">- Qualcomm Innovation Award Winner 2022</small><br/>
            <small style="color:gray;margin-bottom:0.0em">- Presented in AI for Content Creation Workshop (AI4CC) at CVPR 2023</small>
        </p>
      </div>

      <div class="item">
        <img src='./media/fastmetro_teaser.jpg'/>
        <p>
          <b class="title">FastMETRO: Cross-Attention of Disentangled Modalities for 3D Human Mesh Recovery with Transformers</b><br/>
          Junhyeong Cho, <u>Kim Youwang</u>, Tae-Hyun Oh<br/>
          <i>ECCV 2022</i><br/>
            <a href="https://fastmetro.github.io/" target="_blank">Project page</a> |
            <a href="https://arxiv.org/abs/2207.13820" target="_blank">Paper</a> |
            <a href="https://github.com/kaist-ami/FastMETRO" target="_blank">Code</a> |
            <a href="https://www.dropbox.com/s/kzmihz488qcelxi/2116-poster.pdf?dl=0" target="_blank">Poster</a><br/>
        </p>
      </div>

      <div class="item">
        <img src='./media/demr.jpg'/>
        <p>
        <b class="title">Unified 3D Mesh Recovery of Humans and Animals by Learning Animal Exercise</b><br/>
        <u>Kim Youwang</u>, Kim Ji-Yeon, Kyungdon Joo, Tae-Hyun Oh<br/>
            <i>BMVC 2021</i><br/>
            <a href="https://demr-bmvc21.github.io" target="_blank">Project page</a> |
            <a href="https://www.bmvc2021-virtualconference.com/assets/papers/0926.pdf" target="_blank">Paper</a>
        </p>
      </div>

      <h2>Awards & Honors</h2>
        <ul>
            <li class="yw_list">Best Poster Award, BMVC, 2024</li>
            <li class="yw_list">Excellence Prize, Electronics Times ICT Paper Awards, 2024</li>
            <li class="yw_list">Best Poster Award, POSTECH-KAIST joint ML workshop, 2024</li>
            <li class="yw_list">Grand Prize (Minister's award, $12,000 prize), Electronics Times ICT Paper Awards, 2023</li>
            <li class="yw_list">Outstanding Reviewer Award, ICCV, 2023</li>
            <li class="yw_list">Winner ($4,000 prize), Qualcomm Innovation Fellowship Korea (QIFK), 2022</li>
            <li class="yw_list">International Computer Vision Summer School (ICVSS), 2022</li>
        </ul>

      <h2>Talks</h2>
        <ul>
            <li class="yw_list">Towards Efficient & Realistic Virtual World Communication, INNERVERZ, Korea, 2023</li>
        </ul>

      <h2>Academic Services</h2>
        <ul>
            <li class="yw_list">Conference Reviewer: CVPR, ICCV (<a href="https://iccv2023.thecvf.com/outstanding.reviewers-118.php">Outstanding reviewer 2023</a>), ECCV, NeurIPS, BMVC</li>
            <li class="yw_list">Journal Reviewer: TPAMI, ACM TOG/SIGGRAPH Asia, IJCV, TMM</li>
        </ul>

      <h2>Misc.</h2>
        <ul>
            <li class="yw_list">Come visit my <a href="https://www.youtube.com/@kimyouwang" target="_blank">Youtube channel</a>! I sometimes upload paper reviews (in Korean).</li>
            <li class="yw_list">As a guitarist of the <a href="https://www.youtube.com/@postechsteeler1150" target="_blank">band STEELER</a>, I also upload some music covers or gigs.</li>
        </ul>

      <div class="outro">
<!--        template adapted from <a href="https://changilkim.com/" target="_blank">this website</a>-->
      </div>

    </div> <!-- container -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-5RW688RKHW"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-5RW688RKHW');
    </script>
  </body>
</html>
